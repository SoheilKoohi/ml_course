{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/computer_vision.png\" alt=\"computer vision\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computer vision is one of the applications that are rapidly active thanks to deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the applications of computer vision that are using deep learning includes:\n",
    "* Self driving cars.\n",
    "* Face recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of a computer vision problems includes:\n",
    "\n",
    "1. Image Classificaiton "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/image_classification.png\" alt=\"computer vision\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/object_detection.jpg\" alt=\"computer vision\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Image Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/image_segmentation.png\" alt=\"computer vision\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/face_recognition.jpg\" alt=\"computer vision\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Neural Style Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/nst.png\" alt=\"computer vision\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How an Image is Represented in computers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "each gray-scale image can be represented by a 2 dimensional matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/image_matrix.png\" alt=\"computer vision\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However for coloured (RGB) images, we need to employ a three dimensional matrix with three channels. each channel represent one of the red, green and blue color intensity of the image:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/rgb.png\" alt=\"computer vision\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But how we use this matrices as the input of a neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Flattening** is converting the data into a 1-dimensional array for inputting it to a neural network. We flatten the image matrices to create a single long feature vector. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/image_fully_connected.png\" alt=\"computer vision\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the problem with this approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "suppose we want to train a cat/dog classifier for images with sizes 300 by 300.\n",
    "the total number of features for this images would be : $300 \\times 300 \\times 3 = 270000$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of neurons for the first layer of a neural network should not be too much lower than the number of input features because the information of input may be lost in next layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So number of neurons in first layer can be something around $270000/2=135000$\n",
    "The number of trainable parameters for this the first layer is equal to $270000 \\times 135000 = 36450000000$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the number of trainable parameters for this network is enormous and it couses possoble overfitting and intensive computational cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fully connected networks we compute the contribution of every features to reach higher levels feature space.\n",
    "However in images most of the information are local and we can use a sparse network in which for each new feature we just use a group of input pixels and not all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution is a mathematical operator which is highly used in signal processing and image processing to filter images and find informative features such as edges of an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/edge_filter.png\" alt=\"computer vision\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How convolution works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/convolution.png\" alt=\"computer vision\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In CNNs the kernel parameter is learnable and during training phase their values will be updated by gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As suppose the convolution operator finds local features since they apply to a group of pixels in each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also in CNNs the parameter is shared between pixels. This is specially fit for Computer Vision problems. For example a feature detector (such as a vertical edge detector) that's useful in one part of the image is probably useful in another part of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/convolution.gif\" alt=\"computer vision\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last section we saw that a $5 \\times 5$ matrix convolved with $3 \\times 3$ filter/kernel gives us a $3 \\times 3$ matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give it a general rule, if a matrix $n \\times n$ is convolved with $f \\times f$ filter/kernel give us $n-f+1 \\times n-f+1$ matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convolution operation shrinks the matrix if $f>1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to apply convolution operation multiple times, but if the image shrinks we will lose a lot of data on this process. Also the edges pixels are used less than other pixels in an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve these problems we can pad the input image before convolution by adding some rows and columns to it. We will call the padding amount P the number of row/columns that we will insert in top, bottom, left and right of the image.\n",
    "\n",
    "In almost all the cases the padding values are zeros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/padding.png\" alt=\"computer vision\" width=\"250\" height=\"250\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general rule now, if a matrix $n \\times n$ is convolved with $f \\times f$ filter/kernel and padding $p$ give us $n+2p-f+1 \\times n+2p-f+1$ matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $n = 5$, $f = 3$, and $p = 1$ Then the output image will have $n+2p-f+1 = 5+2-3+1 = 5$. We maintain the size of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Same convolutions** is a convolution with a pad so that output size is the same as the input size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strided Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strided convolution is another piece that are used in CNNs.\n",
    "When we are making the convolution operation we used $s$ to tell us the number of pixels we will jump when we are convolving filter/kernel. The last examples we described $s$ was 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the general rule are:\n",
    "if a matrix $n \\times n$ is convolved with $f \\times f$ filter/kernel and padding $p$ and stride $s$ it give us $(n+2p-f)/s + 1 \\times(n+2p-f)/s + 1$ matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most of the times we use strided convolution to down sample the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution in RGB Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw how convolution works with 2D images.\n",
    "For an image with height, width, # of channels of $(h, w, c)$ the convolution filter should have the  same number of channels. Hint that the image number of channels and the filter number of channels are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/rgb_conv.png\" alt=\"computer vision\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Layer of a Convolutional Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "each layer of a convolutional network has a bunch of convolution kernels which are responsible to extract an unique characteristic of the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/conv_layer.png\" alt=\"computer vision\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then a bias vector with shape of $(number\\_of\\_filters, 1)$ will be added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then apply **RELU** will get us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the output of the convolution layer can act like an input image for the next layer, except that the number of channels for this tensor is not necessarily 3 and is equal to number of filters in last layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other than the conv layers, CNNs often uses pooling layers to reduce the size of the inputs, speed up computation, and to make some of the features it detects more robust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/max_pooling.png\" alt=\"computer vision\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example has $f = 2$, $s = 2$, and $p = 0$ hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average pooling is taking the averages of the values instead of taking the max values.\n",
    "Max pooling is used more often than average pooling in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By applying these operators we force the features to be location and orientation invarient. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Typical CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/conv_net.png\" alt=\"computer vision\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "1. When we move forward in a CNN layers the spatial dimension (resolution) will be decrease.\n",
    "2. When we move forward in a CNN layers the number of filters increase.\n",
    "3. At the final stage of a CNN the feature map will fed into a flatten layer and then a fully connected head is responsible for classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras Examples:\n",
    "\n",
    "https://keras.io/examples/vision/image_classification_from_scratch/\n",
    "\n",
    "\n",
    "https://www.tensorflow.org/tutorials/images/classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Famous Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lenet.png\" alt=\"computer vision\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This model was published in 1998\n",
    "* The goal for this model was to identify handwritten digits in a 32x32 gray image.\n",
    "* It has 60k parameters.\n",
    "* The activation function used in the paper was Sigmoid and Tanh. Modern implementation uses RELU in most of the cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Named after Alex Krizhevsky who was the first author of this paper. The other authors includes Geoffrey Hinton.\n",
    "* The goal of the model was to classify images into 1000 classes. Back then this model became the state-of-the-art of ImageNet Challenge.\n",
    "* Has 60 Million parameter compared to 60k parameter of LeNet-5.\n",
    "* It used the RELU activation function.\n",
    "* Multiple GPUs were used because the GPUs were not so fast back then.\n",
    "* This paper convinced the computer vision researchers that deep learning is so important.\n",
    "* Paper: https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf\n",
    "\n",
    "Here are the drawing of the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/alexnet.png\" alt=\"computer vision\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A modification of AlexNet.\n",
    "* Instead of having a lot of hyperparameters lets have some simpler network.\n",
    "* Focus on having only these blocks: CONV = 3 X 3 filter, s = 1, same / MAX-POOL = 2 X 2 , s = 2\n",
    "* This network is large even by modern standards. It has around 138 million parameters.\n",
    "Most of the parameters are in the fully connected layers.\n",
    "* There are another version called VGG-19 which is a bigger version. But most people uses the VGG-16 instead of the VGG-19 because it does the same.\n",
    "* Paper: https://arxiv.org/abs/1409.1556"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/vgg.png\" alt=\"computer vision\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since AlexNet, the state-of-the-art CNN architecture is going deeper and deeper. While AlexNet had only 5 convolutional layers, the VGG network and GoogleNet (also codenamed Inception_v1) had 19 and 22 layers respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, increasing network depth does not work by simply stacking layers together. Deep networks are hard to train because of the notorious vanishing gradient problem — as the gradient is back-propagated to earlier layers, repeated multiplication may make the gradient infinitively small. As a result, as the network goes deeper, its performance gets saturated or even starts degrading rapidly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/deep_error.png\" alt=\"computer vision\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core idea of ResNet is introducing a so-called “identity shortcut connection” that skips one or more layers, as shown in the following figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/res_block.png\" alt=\"computer vision\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors of ResNet found that you can train a deeper NNs by stacking these blocks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a skip-connection helps the gradient to backpropagate and thus helps you to train deeper networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paper: https://arxiv.org/abs/1512.03385"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/resnet.jpg\" alt=\"computer vision\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a large dataset is crucial for the performance of the deep learning model. However in most of the cases gathering large datasets are expensive and sometimes impractical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation is a set of techniques that increase the dataset size by creating different versions of the original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Data Augmentation Techniques in Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/rotation.png\" alt=\"computer vision\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Flipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/flipping.png\" alt=\"computer vision\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/scaling.png\" alt=\"computer vision\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Image Noising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/noising.png\" alt=\"computer vision\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Blurring "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/blurring.png\" alt=\"computer vision\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Cropping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/crop.jpg\" alt=\"computer vision\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conventional machine learning and deep learning algorithms, so far, have been traditionally designed to work in isolation. These algorithms are trained to solve specific tasks. The models have to be rebuilt from scratch once the feature-space distribution changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer learning is the idea of overcoming the isolated learning paradigm and utilizing knowledge acquired for one task to solve related ones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/transfer_learning.png\" alt=\"computer vision\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pretrained models might have trained on a large datasets like ImageNet, Ms COCO, or pascal and took a lot of time to learn those parameters/weights with optimized hyperparameters. This can save you a lot of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/transfer_learning_2.png\" alt=\"computer vision\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed earlier, the initial layers of a deep neural network have been seen to capture generic features, while the later ones focus more on the specific task at hand. \n",
    "So for Transfer Learning we can **freeze** the initial layer's weights and just **fine tune** the final layers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
